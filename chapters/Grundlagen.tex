\chapter{Theoretische Grundlagen}
\label{chap:theoretische_grundlagen} Dieses Kapitel führt in die theoretischen Grundlagen
ein, die in dieser Arbeit benötigt werden. Den ersten Teil bilden die domänenspezifischen
Grundlagen \ref{sec:domänenspezifisch}, welche genauer darauf eingehen, welchen Inhalt
die zu bearbeitenden Bilder bieten und wie dieser zu verstehen ist. Abschnitt
\ref{sec:technologisch} geht anschließend genauer auf die Bildgebung ein, die eine
wichtige Rolle spielen. Der Abschnitt \ref{sec:verwwandte_arbeit} geht auf die
Arbeit von \citet{hoffmann2020} welche das zugrundeligende Verfahren beschreibt.
Die Abschnitt \ref{sec:3d_slicer} führt in Softwareentwicklungsthemen ein, die zum
Erstellen einer \textit{3D Slicer Extention} wichtig sind.
% ---------------------------------------------------------------------------------------

\section{Domänenspezifisch}
\label{sec:domänenspezifisch} Wie bereits aus dem Kapitel \ref{chap:einleitung}
Einleitung klar wurde, handelt es sich bei den Micro-CT Bilder um Zahnbilder. Um
zu verstehen, wie eine CT-Aufnahme technisch segmentiert und damit zerlegt werden
kann, muss zunächst die Zanstruktur selbst verstanden werden.

\begin{minipage}{0.40\textwidth}
	Die Abbildung \ref{fig:aufbau_eines_zahnes} zeigt den groben Aufbau eines Zahnes
	nach \citet[Seite 17]{lehmann2012Zahnheilkunde}. Zu sehen ist, dass das Denit oder
	auch Zahnbein genannt, den Großteil eines Zahnes einnimmt. Im Bereich der Zahnkrone
	wird das Dentin von Zahnschmelz überzogen. Der Zahnschmelz ragt in die
	Mundhöhle und ist nach \citet[Seite 41]{lehmann2012Zahnheilkunde} das härteste
	Material im menschlichen Körper. In der Mitte des Zahnes befindet sich Weichgewebe,
	welches als Pulpa bezeichnet wird vgl. \citep[Seite ]{lehmann2012Zahnheilkunde}.
\end{minipage}
\hfill
\begin{minipage}{0.50\textwidth}
	\centering
	\includegraphics[scale=0.50]{img/aufbau_eines_zahns.jpg}
	\captionof{figure}{Aufbau eines Zahnes nach \citet{lehmann2012Zahnheilkunde}} \label{fig:aufbau_eines_zahnes}
\end{minipage}

Für die Bearbeitung von Micro-CT Aufnahmen sind die Bereich Schmelz Dentin und Pulpa
von besonderer Bedeutung. Betrachtet man eine CT wie es zu Beginn in der
Abbildung \ref{fig:ct_aufnahme_eines_zahns} gezeigt wurde, so bilden diese drei Gewebearten
die unterschiedlichen Grauwerte in einem CT-Bild.

\begin{description}
	\item[\textbf{Die Pulpa}] unterscheidet sich hierbei nur wenig vom Hintergrund,
		da sie als einzige der drei Hauptteile eines Zahnes ein Weichgewebe ist und
		bei einer Röntgenaufnahme nicht absorbiert. Dieser Teil ist in dieser Arbeit
		wenige relevant und auch nicht Teil des Verfahrens, was das
		Segmentierungsverfahren eher zu einer Zahnkronensegmentierung macht. Geht man
		weiter von innen nach außen, so ist der nächste Zahnteil auf einem CT das
		Zahnbein.

	\item[\textbf{Das Dentin}] ist laut \citet[Seite 41]{lehmann2012Zahnheilkunde}
		eine Hartsubstanz, die dem Kieferknochen sehr nah steht. So kommt es, dass
		dieser Teil schon deutlich besser auf einem CT zu erkennen ist. Den äußersten
		Teil in der Mundhöhle bildet das Zahnschmelz.

	\item[\textbf{Der Schmelz}] ist der härteste Teil im menschlichen Körper und aus
		diesem Grund auch am hellsten auf dem CT zu erkennen.
\end{description}

Die folgende Abbildung \ref{fig:pulpa_dentin_schmelz} sollen durch
Gegenüberstellung die einzelnen Zahnsubstanzen auf einer CT Aufnahme
lokalisieren.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{img/dentin_schmelz_pulpa.png}
	\caption{Darstellung von Pulpa, Dentin und Schmelz auf einer CT-Aufnahme nach \citet{heck2024}.}
	\label{fig:pulpa_dentin_schmelz}
\end{figure}

Mit diesem Domänenwissen kann ein Schritt weiter gegangen werden, sodass der
Fokus nun auf die CT-Bilder gesetzt wird. Das Kapitel \ref{sec:technologisch} Bildgebung
führt die Technologie der Computertomografie tiefer ein. Darüber hinaus werden
die verschiedenen Formate und statistische Modelle der CT-Aufnahmen vorgestellt.
% ---------------------------------------------------------------------------------------

\section{Bildgebung}
\label{sec:technologisch} Es gibt die unterschiedlichsten Arten zur Erzeugung
dreidimensonaler Bilddaten. Dieser Abschnitt erläutert federführend die Technologie
der Micro-CT Aufnahmen und deren Erstellung. Diese sind für eine medizinischen
Einsatz besonders interessant. Des Weiteren erfolgt eine Einführung in die Speicherung
und Komprimierung von CT-Aufnahmen. Dies sorgt dafür, dass die digitalen Bilddaten
deutlich handlicher werden.
% ---------------------------------------------------------------------------------------

\subsection{Computertomografie}
\label{subsec:computertomografie} Die Erfindung der Computertomografie (CT) war ein
Quantensprung in der Geschichte der Medizin. Sie ist aus heutigen Diagnosen
nicht mehr wegzudenken. Ein Micro-CT Bild ist laut \citet[Abstract]{baird2017} ein
Menge hochauflösender Bilder, die wie ein Stapel zusammengelegt werden. Der Aspekt
Micro deutet dabei darauf hin, dass es eine miniaturisierte Ausführung eines
üblichen Kegelstrahl-CTs ist, so \citet[Seite 340]{buzug2011}. Eine andere
Definition erläutert \citet{lehmann2013bildverarbeitung}. Er beschreibt die
Computertomografie als Projektionen einzelner Ebenen im Untersuchungsobjekt. Die
Technologie, mit der diese Bilderstapel aufgenommen werden, ist unter der Röntgentechnik
oder auch X-Ray bekannt. Die Röntgenstrahlung ist eine Form der
elektromagnetischen Strahlung, ähnlich wie das sichtbare Licht, so das \citet{nib2024}.
Anders als das Licht haben die Röntgenstrahlen eine viel höhere Energie. Das führt
dazu, dass man mit dieser elektromagnetischen Strahlung viele Objekte
durchdringen kann. So auch Gewebeteile eines Zahnes vgl. \citep{nib2024}. Die
Abbildung \ref{fig:spectrum} zeigt diese elektromagnetische Spektrum.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{img/x_ray.jpg}
	\caption{Einordnung der \ac{X-Ray} nach \citet{zwinkels2015}}
	\label{fig:spectrum}
\end{figure}

Durchdringt ein solcher Röntgenstrahl ein Untersuchungsobjekt, werden die
Details aufgrund der Wechselwirkung mit Materie auf einer CT-Probe sichtbar. Die
bekannteste Wechselwirkung ist die Absorption. Mit der Steigerung der Atomzahl
in einem Material nimmt auch die Absorption eines Materials zu, sodass es leicht
ist verschiedenen Materialien in einer CT-Aufnahme zu unterscheiden \citep[vgl.][]{nib2024}.

Für eine Micro-CT Aufnahme bedarf es spezieller Technik. Es gibt unterschiedliche
Firmen, welche die unterschiedlichsten Modelle anbieten. Im Falle der Zahnklinik
an der LMU in München handelt es sich um ein Micro-CT 40 der Firma \citet{scanco2024}.
Dieses Gerät erstellt Aufnahmen mittels Röntgenstrahlung und generiert mithilfe der
Computertomografie ein dreidimensionales Bild, welches im Format \texttt{.ISQ} abgelegt
wird. Wie das nächste Kapitel beschreiben wird, ist der Speicherumfang den solch
ein Bild benötigt sehr groß, jedoch dafür auch sehr detaliert. Um ein einfacheres
Arbeiten mit den CT Bildern zu ermöglichen, kann eine simple Technik angewendet
werden, die hier beschrieben werden soll.
% ---------------------------------------------------------------------------------------

\subsection{Datenformate}
\label{subsec:datensätze} Die rohen Datensätze, welche direkt aus dem Micro-CT
Gerät kommen, haben nach \citet{scanco2024} das Format \ac{ISQ}. Dieses Format
fällt speziell auf die Geräte der Firma SCANCO zurück. Wie das vorherige Kapitel
\ref{subsec:computertomografie} bereits eingeführt hat, ist dieser Dateityp für
eine weitere Bearbeitung nur bedingt geeignet. Unter anderem wegen ihrer Größe.
\citet{RoeschKunzelmann2018} haben hierfür ein Paket entwickelt. Dieses
konvertiert ein \ac{ISQ} Format in ein \ac{mhd} Format. Bei einer \ac{mhd} Datei
handelt es sich um ein Metafile, dass auf die eigentliche Datei verweist.
Folgender Ausschnitt zeigt die Verwendung des Pakets.

\texttt{python3 isq\_to\_mhd.py <quelle> <ziel>}

Diese Meta-Datei kann genutzt werden, um interessante Informationen über das Bild
zu erlangen. Wird dieses Kommando ausgeführt, so erstellt das Skript \texttt{isq\_to\_mhd}
ein Metafile, das detailliert Daten über die Datei enthält. Ein Ausschnitt
dieses Metafiles liefer das Listing \ref{lst:inhalt_mhd_datei}

\begin{lstlisting}[
	caption={Ausschnitt des Inhaltes einer mhd-Datei},
	label={lst:inhalt_mhd_datei}]
ObjectType = Image
NDims = 3
CenterOfRotation = 0 0 0
ElementSpacing = 0.02 0.02 0.02
DimSize = 1024 1024 517
ElementType = MET_SHORT
ElementDataFile = P01A-C0005278.ISQ
\end{lstlisting}

In der Datei sind Informationen über die Ausprägung, Art und Größe der Datei zu finden.
Besonders interessant sind die Punkte \texttt{DimSize und ElementType}. Über
diese Parameter lässt sich die Größe eines Bildes berechnen. \citet[Seite 10-11]{burger2009}
erklärt, das ein Bild in Zellen aufgeteilt ist, welche Informationen enthalten.
Diese Zellen sind im zweidimensionalen Raum als Pixel bekannt. Betrachtet man jedoch
ein, wie im Falle der Zahnklinik an der LMU dreidimensionales Bild, so spricht man
nicht mehr von einem Pixel, sondern von einem Voxel. Ein Voxel ist demnach das dreidimensionale
Äquivalent zu einem Pixel. \citet[Seite 10-11]{burger2009} beschreibt weiter das
jeder diese Zellen ein binäres Wort der Länge $2^{k}$ ist. Die Basis 2 ergibt sich
durch das binäre Wort, wo hingegen für $k$ gilt: $k \in \mathbb{N}$. Um für den
konkreten Fall aus Listing \ref{lst:inhalt_mhd_datei} das entsprechenden $k$ zu
ermitteln, muss der \texttt{ElementType} näher betrachtet werden. \texttt{MET\_SHORT}
steht hierbei für Signed short, was eine Größe von 16 Bit entspricht. Damit
ergibt sich für die Länge $k$ ein Wert von 4. So können nach \citet[Seite 10-11]{burger2009}
folgende Gleichungen festgehalten werden.

\begin{align}
	\label{equ:größe_bestimmen}1024 \cdot 1024 \cdot 517    & = 542,113,792 \, \text{Voxel}\notag  \\
	542,113,792 \, \text{Voxel}\cdot 2 \, \text{Byte/Voxel} & = 1,084,227,584 \, \text{Byte}\notag \\
	1,084,227,584 / 1,000,000,000                           & = 1.0842 \, \text{GB}
\end{align}

Die erste Gleichung bestimmt die Gesamtzahl aller Voxel in einem Bild. Gleichung
2 ermittelt die Größe des Bildes in der Einheit Byte. Die letzte Zeile nimmt eine
Umrechnung von Byte nach Gigabyte (GB) vor.

Durch die Gleichungen in \ref{equ:größe_bestimmen} wird klar, das eine CT-Aufnahme
des Typs \texttt{.ISQ} direkt nach seiner Aufnahme über einen GB groß ist. Laut
\citet{poliklinikLMU} ist dies ein zu großes Format. Es stellt sich also die
spannende Frage, wie solch eine Datei komprimiert werden kann, ohne das es
Verluste in der Qualität gibt. Dr. Elisa Walter hat hierfür eine Lösung
entwickelt. QUELLE Betrachtet man den \texttt{ElementType} genauer, so fällt auf,
dass es noch weiter Typen gibt, die durch eine geringere Länge $k$ deutlich weniger
Speicher benötigen. Durch Anwendung simpler Statistik lässt sich herauslesen, das
die $2^{4}$ Byte je Element nicht ausgenutzt werden. Als Werkzeug für die
Betrachtung einer solchen Statistik kann das Histogramm eines Bildes genutzt
werden. Laut \citet[Seite 249]{jahne2024} ist ein Histogramm die Häufigkeitsverteilung
der Grauwerte. Diese zeigt Grafisch die unterschiedlichen Grauwerte (X-Achse) zu
ihren Häufigkeiten im Bild (Y-Achse). \citet[Seite 249]{jahne2024} macht deutlich,
dass das Histogramm jedoch kein Aufschluss über die räumliche Verteilung der
Pixel oder Voxel liefert. Werden einige der Argumente nicht verwenden, so kann
der \texttt{ElementTyp} verkleinert werden
% ---------------------------------------------------------------------------------------

\section{Bildbearbeitung}
\label{sec:bildbearbeitung} Nachdem ein CT erzeugt und gegebenenfalls
komprimiert wurde, folgt die Bearbeitung eines Bildes. Hierfür bietet das
Pipeline-Modell von \citet[Seite 50]{handels2000} eine gute Richtlinie. Er beschreibt
mit dieser Visualisierungs-Pipeline Schritte, die bei der Bearbeitung von
dreidimensionalen CT-Aufnahmen notwendig sind \citep[vgl.][Seite 50]{handels2000}.
Die ersten Schritte, \textit{Bildvorverarbeitung} und \textit{Segmentierung}, sind
von besonderem Interesse. Dieser Abschnitt orientiert sich an dieser
Unterteilung und nimmt sie als Vorbild. Daraus ergeben sich die Abschnitte \ref{subsec:filter}
Filter und \ref{subsec:segmentierung} Segmentierung, welche die Pipelineschritte
\textit{Bildvorverarbeitung} und \textit{Segmentierung} wiederspiegeln sollen.
% ---------------------------------------------------------------------------------------

\subsection{Filter}
\label{subsec:filter} CT-Aufnahmen rauschen, dies ist ein Fakt und liegt in der Natur
einer Röntgenaufnahme. Dies beschreiben auch \citet[Kapitel 3]{diwakar2018} in
ihrem Paper über CT-Bildrauschen und Entrauschen. Dabei liegt die Ursache des Rauschens
nicht an einer Stelle sondern ist auf viele Quellen zurückzuführen. Einen gute
Einteilung dieser Quellen liefern ebenfalls \citet[Kapitel 3]{diwakar2018}. Sie teilen
die Rauschquellen auf in \textit{Random noise, Statistical noise, Electronic
noise und roundoff noise}.

Unter dem Rauschen eines Bildes versteht man die Streuung der Pixelwerte im Bild.
Für eine Segmentierung des Bildes ist dieses Verhalten unerwünscht und führt zu schlechten
Ergebnissen \citep[vgl.][Seite 51]{handels2000}. Die Bildvorverarbeitung oder
auch Filter gennant, hat die Aufgabe dieses Rauschen so gut wie möglich zu redzieren.
Hierzu gibt es diverse Möglichkeiten.

\begin{minipage}{0.40\textwidth}
	Mit Blick auf die folgenden Kapitel sind für diese Arbeit vorallem die lokalen
	Operatoren relevant. Die lokalen Operatoren sind charakteristisch für die
	Betrachtung der lokalen Nachbarschaft. Jeder Pixel betrachtet also seine Umgebung
	und führt auf Basis darauf eine Berechnung des jeweils betrachteten Pixels durch.
	in Abbildung \ref{fig:lokaler_operator_maske} ist der aktuelle Pixel der mit
	der Position $P = (0/0)$ \citep[vgl.][Seite 52]{handels2000}.
\end{minipage}
\hfill
\begin{minipage}{0.50\textwidth}
	\centering
	\includegraphics[width=0.60\textwidth]{img/lokaler_operator_maske.jpg}
	\captionof{figure}{Maske eines lokalen Operators nach \citet[Seite 52]{handels2000}}
	\label{fig:lokaler_operator_maske}
\end{minipage}

Für die konkrete Betrachtung der Nachbarschaft eines Pixels empfiehlt \citet[Seite
52]{handels2000} eine Maske (Ausschnitt) herranzuziehen, die mit einer Matrix
interpretiert werdenen kann und die Nachbarschafft eines Pixels abbildet. Abbildung
\ref{fig:lokaler_operator_maske} zeigt eine sollche Maske und soll das Verfahren
so verdeutlichen. Der grau hinterlegte Mittelpunkt - $P = (0/0)$ - ist das
aktuell betrachtete Pixel. die Felder um die Mitte herum die Nachbaren. Es fällt
jedoch auf, dass durch dieses Schema nicht jede mögliche Ausprägung einer Maske in
frage kommt. Um ein Mittelpunkt und damit einen aktuellen Pixel betrachtetn zu
können, bedarf es eines ungeraden Grades für $M$. Diese Eingränzung lässt sich
in Gleichung \ref{equ:lokaler_operator} generisch fassen.

\begin{align}
	\label{equ:lokaler_operator}M_{(2_m+1)x(2_m+1)} & = \begin{bmatrix}k_{11}&k_{12}&k_{13}\\ k_{21}&x&k_{23}\\ k_{31}&k_{32}&k_{33}\\\end{bmatrix} & m \in \mathbb{N}
\end{align}

Die Gleichung \ref{equ:lokaler_operator} beschreibt die mögliche Ausprägung eines
lokalen Operators als Matrix. Dabei sei $m \in \mathbb{N}$. Die Variable $x$ beschreibt
das aktuell betrachtete Pixel, während $k_{nn}$ die Nachbarn illustrieren soll. Durch
die Gleichung ist auch zu erkennen, das die Maske des lokalen Operators beliebig
groß werden kann. Eine hohe Ordnung der Operatormatrix ist jedoch nicht immer von
Vorteil, sodass es letzten Endes auf den Anwendungsfall ankommt.

Mit der Technik der lokalen Operatoren können nun unterschiedliche Arten
angwenden werden. \citet[Seite 54 - 55]{handels2000} unterscheidet hier in Glättungsfilter,
Mittelwertfilter, Medianfilter, Gaußfilter und Binomialfilter. Alle dieser Filter
bedienen sich einer Operatormaske um auf Basis der Nachbarelementen ein Statistischen
Wert für den Bildpunkt zu erhalten. Um einen genaueren Einblick in alle Filter
zu erlangen, sei an dieser Stell auf \citet[Seite 54 - 55]{handels2000} verwiesen.

Wie zu Anfang dieses Kapitels beschrieben, ist eine Bildvorvearbeitung (Filterung)
für eine gute Segmnetierung des Bildes unerlässlich. So kommt es das auch in der
Visualisierungs-Pipelin nach \citet[Seite 50]{handels2000} der zweite Schritt bereits
die Segmentierung einführt. Warum dies so ein wichtiger Bestandteil der
Bildanalyse ist und welche Methoden sich hier bieten, erläutert das folgende Kapitel.
% ---------------------------------------------------------------------------------------

\pagebreak

\subsection{Segmentierung}
\label{subsec:segmentierung} Die Bildsegmentierung oder auch Bildaufteilung
genannt, ist ein wichtiges Teilgebiet der Bildverarbeitung und beschäfftigt sich
mit der Bildanalyse. Ihr Ziel ist es, detailirtere beschreibende Bilder aus dem vorliegenden
Orginalbild zu berechnen. Dies kann im Falle eines CTs der Zahnklinik an der LMU
München die hervorgehobene Darstellung der Zahnsubstanzen Schmelz und Dentin
sein. \citep[vgl.][Seite 359]{lehmann2013bildverarbeitung}. Konkret teilt ein
Segmentierungsverfahren also ein Bild in Teilbereiche auf. Dabei sind die Teilbereich
in sich bemerkenswert homogen. \citet[Seite 1]{ramesh2021} beschreiben, dass der
Prozess der Segmentierung zur Gewinnung wichtiger Informationen dient wie zum Beispiel
die Zahnkaries Ausbreitung. So kommt es, dass \citet[Seite 50]{handels2000} in seiner
Visualisierungs-Pipelin die Segmentierung als zweiten Schritt und damit als zentrales
Problem darstellt. \citet[Seite 95]{handels2000} und \citet[Seite 360]{lehmann2013bildverarbeitung}
beschreiben beide, dass die Bildsegmentierung eines CTs für eine gute und eindeutige
Ärzliche Diagnose nicht mehr wegzudenken ist. Warum dem so ist, verdeutlicht die
Abbildung \ref{fig:interpretation_einer_ct_aufnahem}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{img/bild_interpretation.jpg}
	\caption{Interpretation einer CT-Aufnahme nach \citet[Seite 360]{lehmann2013bildverarbeitung}}
	\label{fig:interpretation_einer_ct_aufnahem}
\end{figure}

Zu erkennen ist das orginale Bild (Ausgangslage) und mögliche
Interpretationsschritte (Interpretation1 und Interpretation2). \citet[Seite 360]{lehmann2013bildverarbeitung}
verdeutlichen mit dieser Abbildung \ref{fig:interpretation_einer_ct_aufnahem},
dass mittels Segmentierung die einzig mögliche Interpretation die erste ist. Auch
wenn die zweite Interpretation die deutlich logischere ist, kann diese ohne
weitere Forschung nicht bewiesen werden, so \citet[Seite 360]{lehmann2013bildverarbeitung}.
Ausßerdem ist zu erkennen, dass die Abbildung \ref{fig:interpretation_einer_ct_aufnahem}
die Definition einer Segmentierung belegt. Die Erzeugung inhaltlich
zusammengehöriger Regionen werden hier durch die verschiedenen Formen
visualisiert \citep[vgl.][Seite 360]{lehmann2013bildverarbeitung}.

Um ein Bild zu segmentieren gibt es unzählige Möglichkeiten. Für die Auswhal eines
Verfahrens spielt unter Anderem der Anwendungsbereich eine wichtige Rolle. Die
Verfahren, die in dieser Arbeit von Wichtigkeit sind, sind die
Schwellwertverfahren \citep[vgl.][Seite 361]{lehmann2013bildverarbeitung}.

\pagebreak

\textbf{Schwelltwertverfahren} (engl.: thresholding) gehören zu den
Standardwerkzeugen einer Segmentierung, sodass sie die Basis vieler weiterer Verfahren
legen. Bei einer Schwellwertbasierten Segmentierung werden die Pixel eines
Bildes anhand von Schwellwerten eingruppiert \citep[vgl.][Seite 96]{handels2000}.
Die nachfolgende Gleichung \ref{equ:schwellwertverfahren} soll dies verdeutlichen.

\begin{align}
	\label{equ:schwellwertverfahren}B(x, y, z) = \begin{cases}1,&\text{falls }t_{\text{unten}}\leq f(x, y, z) \leq t_{\text{oben}}, \\ 0,&\text{sonst}.\end{cases}
\end{align}

$B(x, y, z)$ Beschreibt einen Pixel in einem dreidimensonalen Bild, demnach ein Voxel.
Liegen die Werte eines Voxels, also $f(x, y, z)$, innerhalb der beiden
Schwellwerte $t_{oben}$ und $t_{unten}$, dann wird eine 1 zugewiesen. Liegt der
aktuell betrachtete Voxel nicht zwischen den Schwellwerten, so wird eine 0 zugewiesen.
Das Ergebnis einer solchen primitiven Schwellwertsegmentierung ist in Abbildung
\ref{fig:binäres_schwellwertverfahren} zu sehen

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{img/beispiel_schwellwertverfahren.jpg}
	\caption{Ergebnis eines einfachen Schwellwertverfahrens nach \citet[Seite 96]{handels2000}}
	\label{fig:binäres_schwellwertverfahren}
\end{figure}

Zu erkennen ist, dass nach einem einfachen Schwellwertverfahren das Bild nur noch
aus zwei unterschiedlichen Graustufen besteht. Betrachtet man das Ergbnis in
\ref{fig:binäres_schwellwertverfahren} genauer, so ist abgesehen von der Sinnhaftigkeit,
diese einfach Segmentierung durchaus erfolgreich verlaufen. Der Grund dafür ist die
gute Wahl des Schwellwertes.

Die interessanteste Frage bei den Schwellwertverfahren ist die Wahl des Schwellwertes
$t$. Dieser entscheident zwischen einer guten und einer schlechten Segmentierung.
Für die Wahl eines Schwellwertes empfielt sich der Blick auf das Bildhistogramm.
Dieses gibt Aufschluss über die Grauwertverteilung eines Bildes \citep[vgl.][Seite361]{lehmann2013bildverarbeitung}.
Verfahren, welche eine gute Schwellwertwahl gewährleistet, ohne das zu viele Informationen
verloren gehen, sind die Verfahren \textit{Otsu} und \textit{Renyi}.

\pagebreak

\textbf{Das Verfahren nach Otsu} gehört zu den Schwellwertverfahren und bestimmt
den Schwellwert $t$ durch ein statistische Gütekriterieum. Hierzu bedient sich das
Verfahren des Bildhistogrammes. Die räumliche Anordnung der Voxel und damit das
tatsächliche Bild, benötigt dieser Algorthmus nicht \citep[vgl.][Seite 264]{lehmann2013bildverarbeitung}.

\begin{minipage}{0.40\textwidth}
	Ein solches Histogramm, welches die Grundlage für für das Verfahren nach Otsu
	liefert sei in Abbildung \ref{fig:histogramm} gezeigt. Dies gibt Aufschluss über
	die unterschiedlichen Grauwerte und wie oft sie in einem Bild vorkommen \citep[vgl.][Seite264]{lehmann2013bildverarbeitung}.
	Für eine genauere Beschreibung eines Histogrammes, sei an dieser Stelle auf \citet[Seite42]{burger2009}
	verwiesen.
\end{minipage}
\hfill
\begin{minipage}{0.50\textwidth}
	\centering
	\includegraphics[width=1\textwidth]{img/histogramm.jpg}
	\captionof{figure}{Histogramm einer Zahnaufnahme nach Hoffmann} \label{fig:histogramm}
\end{minipage}

Das Otsu-Verfahren teilt die Grauwerte eines Bildes in verschiedenen Klassen ein,
die durch Schwellwerte getrennt werden. Die Klassen können beispeilsweise mit
$K_{0}$ bis $K_{n}$ bezeichnet werden, wobei sich dieses konkrete Beispiel auf die
Klassen $K_{0}$ und $K_{1}$ beschränkt. Otsu wählt den Schwellwert $t$, der die Varianz
zwischen den Pixelklassen maximiert und gleichzeitig die Varianz innerhalb jeder
Klasse minimiert \citep[vgl.][Seite264]{lehmann2013bildverarbeitung}.
Matematisch lässt sich dies wie folgt ausdrücken.

\begin{align}
	t = \text{max }(\sigma_{zw}^{2}/ \sigma_{in}^{2})
\end{align}

$\sigma_{zw}$ bildet die Varianz zwischen den beiden Klassen $K_{0}$ und $K_{1}$
und wird gebildet aus der Wahrscheinlichkeiten mit denen jeder einzelne Grauwert
auftritt. $\sigma_{in}$ hingegen, ist die Varianz innerhalb einer Klasse und entsteht
durch die Addition der Varianzen der einzelnen Klassen. Der Schwellwert $t$ ist
nun der, für den das Verhältnis maximal wird \citep[vgl.][Seite264]{lehmann2013bildverarbeitung}.

Laut \citet[Seite264]{lehmann2013bildverarbeitung} fällt auf, dass dieses
Verfahren vorallem bei bimodalen Bildern zum Einsatz kommt. Ein Bild ist bimodal,
wenn es zwei lokale Maxima aufweist. Das Otsu-Verfahren ist jedoch nicht auf eine
Bimodalität beschränkt und kann auf beliebig viele Klassen erweitert werden \citep[vgl.][Seite264]{lehmann2013bildverarbeitung}.

Eine ganz ähnliche Technik für die bestimmung des Schwellwertes liefert das Verfahren
der Renyi Entropie. Auch hier ist eine einteilung der Voxel in Klassen
vorgesehen.
% ---------------------------------------------------------------------------------------
\pagebreak

\textbf{Das Verfahren nach Rényi} ist ein weiteres Verfahren, das im Laufe
dieser Arbeit noch eine wichtige Rolle spielt. Wie bereits Beschrieben gehört es
ebenfalls zu der Gruppe der Schwellwertverfahren und genneriert demnach ein Schwellwert
$t$. Wie auch das Verfahren nach Otsu, benötigt Rényi keine Information über die
räumliche Anordnung der Bilder, es genügt das Bildhistogramm. Dabei ist der optimal
Schwellwert $t$ der, der eine maximale Entropie der Bildverteilung erzeugt. Unter
einer Entropie wird ein Konzept verstanden, das eine Unordung, Unsicherheit oder
den Informationsgehlat innerhalb eines Systems beschreibt, so \citet{bein2006}.
Die Rényi-Entropie ist eine Verallgemeinerung der Shannon-Entropie und hängt von
einem Parameter $q$ ab. Die Entropie misst die Unsicherheit oder den Informationsgehalt
einer Wahrscheinlichkeitsverteilung, welche sich wie folgt ausdrücken lässt
\citep[vgl.][K. 2]{bromiley2004}.

\begin{align}
	H_{q}(P) = \frac{1}{1-q}\ln \left( \sum_{i=1}^{N}p_{i}^{q}\right)
\end{align}

Besonderes Augenmerk verdienen hierbei die Paramter $p_{i}$ und $q$, welche di charakteristischen
Eigenschaften der Rényi-Entropie beschreiben. Der Parameter $p_{i}$ ist die
Wahrscheinlichkeit eines jeden Grauwertes im Bild. $i$ symbolisiert hierbei jeden
Grauwert. Wie viele Grauwerte genau betrachten werden sollen definiert $N$. Die Variable
$q$ hingegen beeinflusst die Gewichtung der Wahrscheinlichkeit $p_{i}$ für jeden
Grauwert. Setzt man den Parameter $q$ auf $q = 1$ so lässt sich so mittels
Algebra die Shannon-Entropie zeigen \citep[vgl.][K.2]{bromiley2004}. Um nun mit
der Rényi-Entropie den optimalen Schwellwert für ein Bild zu berechnen sieht
Rényi ähnlich wie Otsu eine Einteilung in Klassen vor. Die Einteilung erfolgt mittels
des Parameters $N$. So kann nun für jede gebildete Klasse die Gleichung ...
angewendet werden. Die Gesamtentropie des Systems wird aus den beiden Teilentropien
der jeweiligen Klassen bestimmt\citep[vgl.][K. 2]{bromiley2004}.
\begin{align}
	H_{q}(T) = H_{q}(P)^{(1)}+ H_{q}(P)^{(2)}
\end{align}
Um nun den optimalen Schwellwert $t$ bestimmen zu können muss der Wert genommen
werden, bei dem die Gesamtentropie des Systems maximal ist. Dieser Sachverhalt
lässt sich wie folgt ausdrücken \citep[vgl.][K. 2]{bromiley2004}.
\begin{align}
	t = max(H_{q}(T))
\end{align}
Neben unzähligen weiteren Segmentierungstechniken, ist eine für diese Arbeits von
ganz besonderer Bedeutung. Diese Technik wurde speziell zum Segementieren der
Micro-CT bilder des Zahnklinikums an der LMU in München entwickelt und bildet
die Basis dieser Arbeit. Konkret ist damit das Hoffmann-Verfahren gemeint \citep[vgl.][]{hoffmann2020}.

\pagebreak
% ---------------------------------------------------------------------------------------

\section{Verwandte Arbeit}
\label{sec:verwwandte_arbeit} Wie bereits in der Einleitung dieser Arbeit klar wurde
verfügt die Poliklinik für Zahnerhaltung und Parodontologie des LMU-Klinikums München
über einen breiten Schatz an Bilddaten. Im Rahmen einer Bachelorarbeit an der
Hohschule für angewnadte Wissenschafften in Augsburg unterstützte \citet{hoffmann2020}
die Verarbeitung dieser Bilddaten mit Methoden der 3D-Bildverarbeitung. Konkret
sollte die Arbeit die Kariesklassifizierung unterstützen. Hierzu entwickelte er ein
Verfahren, das auf Basis adaptiver Schwellwertverfahren die Zahnsubstanzen
Schmelz und Dentin aus dem Orginalbild herrauslöst. Konkret kann diese Segmentierung
mit verschiedenen Verfahren durchgeführt werden. Man spricht hier von einer
anatomsichen Segmentierung der Zahnkrone.

\begin{minipage}{0.45\textwidth}
	Durch die Segmentbetrachtung der Beiden Zahnhauptteile Schmelz und Dentin konnte
	\citet{hoffmann2020} eine gute Hilfe für die Befundung kariöse Stellen liefern.
	Ein Ergebnis aus der Arbeit von Hoffman sei in Abbildung \ref{fig:ergebnis_hoffmann}
	gezeigt. \citet{hoffmann2020} entwickelte hierfür ein Prototypisches Verfahren,
	mit dem es gelang ca. 250 Datensätze der Zahnklinik automatisch aufzubereiten.
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
	\centering
	\includegraphics[width=0.7\textwidth]{img/ergebnis_hoffmann_2.jpg}
	\captionof{figure}{Reproduzierte Ergebnisansicht der anatomischen Segmentierung}
	\label{fig:ergebnis_hoffmann}
\end{minipage}

Die anatomischeSegmentierung des Zahns umfasst ein ganze Reihe algorithmischer Schritte,
sodass sich eine Pipeline an Verarbeitungsschritten ergibt. Die Abbildung \ref{fig:anatomische_segmentierung}
zeigt den groben Ablauf des Verfahrens. Kleinere Zwischenschritte wurden nicht
berücksichtig.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{img/anatomischeSegmentierung.png}
	\caption{Algorithmische formulierung der anatomischen Segmentierung nach
	\citet{hoffmann2020}}
	\label{fig:anatomische_segmentierung}
\end{figure}

\citet{hoffmann2020} beschreibt, dass dieses Verfahren bis zu einem gewissen Vortschritt
des Karies durchgeführt werden konnte, da der Algorithmus diesbezüglich seine
Grenzen hat. Außerdem ist das Verfahen für die orginalen ISQ-Bilder erstellt worden,
deren Daten im Format \ac{16Int} vorliegen. Für die Spätere Darstellung der
Ergebnisse kann eine überlappende Ansicht in einer Visualisierungssoftware
verwendet werden. So ergibt sich die Situation, dass der Algorithmus ein gutes
Ergebnis liefert, jedoch nicht benutzerfreundlich zu bedienen ist. Für das
Starten und Visualisueren des Verfahrens sind aufwendige Befehle über das
Terminal zu tippen \citep[vgl.][Seite 53]{hoffmann2020}. Genau an dieser Stelle soll
die vorliegende Arbeit anknüpfen und das Verfahren nach \citet{hoffmann2020} so
interaktiv und benutzerfreundlich gestallten.

Für eine interaktive Verarbeitung von 3D Bilddaten bieten sich einige
Möglichkeiten. Die wohl beste Lösung liefer 3D Slicer. Warum die Wahl auf diese
Plattform viel und welche Vorteile daraus entstehen wird im folgenden Abschnitt
\ref{sec:3d_slicer} erläutert.

\pagebreak
% ---------------------------------------------------------------------------------------

\section{Interaktive Bildbearbeitung mit 3D Slicer}
\label{sec:3d_slicer} 3D Slicer ist eine Open Source Plattform, die speziel für
die Verarbeitung für Bilddaten im medizinischen Kontext eingesetzt wird. Dabei wird
sie von einer aktiven Community regelmäßig gewartet und weiterentwickelt \citep[vgl.][]{slicer2024},
\citep[vgl.][]{fedorov2012slicer}. Für Slicer gibt es offizell keine Nutzungsbeschränkung.
Jedoch sei auch gesagt, dass 3D Slicer nicht für die klinische Nutzung zugelassen
ist. \citet{fedorov2012slicer} macht deutlich, das 3D Slicer ausschließlich für
die Forschung gedacht ist. Um einen ersten Überblick über die Komponenten von Slicer
zu erlangen, soll die Abbildung \ref{fig:3d_slicer_oekosystem} betrachtet weden.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{img/3d_slicer_overview.jpg}
	\caption{3D Slicer Ökosystem nach \citet[Seite 1326]{fedorov2012slicer}}
	\label{fig:3d_slicer_oekosystem}
\end{figure}

\citet[Seite 1326]{fedorov2012slicer} Teilt mit der Abbildung \ref{fig:3d_slicer_oekosystem}
die Plattform in drei Schichten auf. Auf der obersten wird klar, dass 3D Slicer aus
der Kernanwendung und den Installierbaren Modulen besteht. Neben den bereits
vorhandenen Modulen können von externen Entwicklern Module über die Slicer
Extentions entwickelt und bereitgestellt weden. Um eine Weiterentwicklung möglich
zu machen hat Slicer eine Reihe von Abhängigkeiten, die jedoch portabel gehalten
werden. Auf der untersten Schicht sind die Platformspezifischen Anforderungen zu
sehen, die Slicer erfüllen soll.

So kommt es, dass das 3D Slicer Ökosystem sich durch einige Kriterien besonders auszeichnet.
Die wohl wichtigsten seien hier Stichpunktartig genannt \citep[vgl.][]{slicer2024},
\citep[vgl.][]{fedorov2012slicer}.

\begin{itemize}
	\item Kostenfreie Software

	\item Plug-In Infrastruktur durch den Extention Manager

	\item Ausführen von Skripten in der integriertetn Python Konsole

	\item Verarbeitung von medizinischen Bilddaten von Kopf bis Fuß

	\item Interaktive Benutzerschnittstelle
\end{itemize}

3D Slicer hat für alle diese Punkte jeweils eine Lösung entwickelt, wobei der erste
Punkt durch die Open Source Philosiphie schon gegeben ist. Die folgenden
Abschnitte decken diese Lösungen ab und bilden so eine erste Grundlage für die
Entwicklung mit 3D Slicer\citep[vgl.][]{slicer2024}, \citep[vgl.][]{fedorov2012slicer}.
% ---------------------------------------------------------------------------------------

\subsection{Extension Manager und Plugin Infrastruktur}
Der wohl bedeutenste Punkt ist die Plug-In Infrastruktur, welche Slicer von sich
aus mitbringt. Um dieses Konzept genauer zu beläuchten Teilt man die Platform am
besten in zwei Teile auf. Die Kernanwendung und die Module, welcher jeder User
personalisiert installieren oder deinstallieren kann. Diese Module werden als \textit{Slicer
lodabel module} bezeichnet \citep[vgl.][Seite 1332]{fedorov2012slicer}. Slicer realisiert
die Struktur durch den Extention Manager, welcher durchaus vergleichbar ist mit
einer Art AppStore. Über diesen können bequem und mit wenig Klicks die gewünschten
Erweiterungen in das Kernsystem installiert werden.

\begin{minipage}{0.30\textwidth}
	Neben der Möglichkeit Module zu installieren bietet Slicer noch die Möglichkeit
	eigenen Module zu bauen und Sie im Extention Manager zu veröffentlichen. Diese
	werden als \ac{SEM} bezeichnet. Hierzu verfolgt Slicer den Ansatz, dass jeder Entwickler
	eines Moduls selbst verantwortlich für Wartung und Weiterentwicklung ist. Auch
	nachdem ein Paket veröffentlicht wurde \citep{slicer2024}.
\end{minipage}
\hfill
\begin{minipage}{0.60\textwidth}
	\centering
	\includegraphics[width=1\textwidth]{img/slicer_extention_index.png}
	\captionof{figure}{Funktionsweise der Plugin Infrastruktur von 3D Slicer nach \citet{extensionsIndex2024}}
	\label{fig:3d_slicer_extension_index}
\end{minipage}

Slicer realisiert dies, indem die Plattform über ein zusätzliches Reporsitory verfühgt,
dass sich
\href{https://github.com/Slicer/ExtensionsIndex?tab=readme-ov-file}{\textit{ExtensionIndex}}
nennt. Dieses öffentliche Repository ist eine Auflistung aller Slicer Extentions.
Die Auflistung erfolgt durch eine Reihe an \ac{JSON} Datein, die auf die
Repositories der einzelnen Entwickler verweisen. Dieser \href{https://github.com/Slicer/ExtensionsIndex?tab=readme-ov-file}{\textit{ExtensionIndex}}
ist über die Slicer Factory an den Extention Server und damit auch an den Extention
Manager angebunden. Die Slicer Factory ist ein System, das aus einem Slicer Extention
Repository ein lauffähiges Build erstellt, welches in den Extention Katalog
eingebunden werden kann. Ist eine Extention in dem Extention Katalog gelistet,
so sorgt der Extention Manger dafür, dass die von der Slicer Factory erstellt build-Datei
installiert werden kann. Abbildung \ref{fig:3d_slicer_extension_index} soll
diesen Vorgang verdeutlichen \citep[vgl.][]{slicer2024}.

Die Kernanwendung von 3D Slicer folgt einem Softwarepattern, dass sich \ac{MVC} nennt.
Bei der Erstellung einer \ac{SEM} soll dieser Ansatz ebenfalls gepflegt werden.
Eine High Level Betrachtung der Softwarearchitektur von 3D Slicer bietet
\cite[Seite 1332]{fedorov2012slicer} mit der Abbildung
\ref{fig:3d_slicer_architektur}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{img/3d_slicer_architektur.jpg}
	\caption{3D Slicer High Level Architektur nach \citet[Seite 1326]{fedorov2012slicer}}
	\label{fig:3d_slicer_architektur}
\end{figure}

Das Zusammenspiel zwischen \ac{MRML}, \ac{GUI} und der Logic bilden das MVC-Pattern
in der Kernanwendung. Das indentische Pattern spiegelt sich auch in den einzelnen
Modulen von Slicer wieder. So wird sichergestellt, dass ein Softwareentwicklungsparadigma
eingehalten wird, was sich \textit{separation of concerns} nennt. Die Kapselung
von zusammengehöriger Logik. Bei der Erstellung einer eigenen Extention ist die Idee,
dass nur die Logic implementiert werden muss und die komplexe Architektur von
Slicer erstmal nicht relevant ist.

Jedoch bietet sich in Slicer nicht nur die Möglichkeit eigenen Erweiterungen zu
erstellen. Es lässt sich hierfür auch die integrierte Python Konsole nutzen.
% ---------------------------------------------------------------------------------------

\subsection{Python Umgebung}
\label{subsec:pythob_umgebung} 3D Slicer bringt eine integrierte Python Konsole mit,
über die mit der Datenstruktur interagiert werden kann. So ist es möglich Python
Skripte direkt in der Konsole auszuführen. Um dies zu realisieren bringt Slicer
mit der Installation im jeweiligen Betriebssystem eine eigenen Python Umgebung
mit. Dieses sieht wie folgt aus.

\texttt{./Slicer/bin/PythonSlicer}

Diese Python Umgebung verfügt über alle notwendigen Abhängigkeiten und Pakete.
Bei der Entwicklung eines SEM kann dann auf die Pip-Pakete in der integrierten
Python Umgebung zurückgegriffen werden. So kommt es das für eine Entwicklung mit
Slicer keine eigenen Python Umgebung auf der lokalen Maschine installiert sein muss.
Slicer bringt hier alls mit.

Für den letzten charakteristischen Punkt von Slicer aus Kapitel
\ref{sec:3d_slicer} führt der nächste Abschnitt in die durchaus komplexe
Datenstruktur MRML ein, die bei einer Entwicklung mit Slicer unausweichlich zu berücksichtigen
ist.
% ---------------------------------------------------------------------------------------

\subsection{MRML Datenstruktur}
\label{subsec:mrml_datenstruktur} Die \ac{MRML}, gesprochen \textit{"Murlm"} ist
ein Datenmodell das dafür entwickelt wurde alle möglichen Bilddaten zu
visualisieren und zu speichen, die für einen klinischen Zweck Einsatz finden \citep[vgl.][]{slicer2024}.
Laut der \citet{slicer2024} wurde die MRML-Datenstruktur völlig unabhängig von
der Slicer Kernanwedung entwickelt. Dies ermöglicht ein portieren der Datenstruktur
auf andere Softwareapplikationen. Da Slicer die einzig große Plattform ist, die diese
Datenstruktur nutzt, wird der Quellcode für MRML im Reporsitory von 3D Slicher
gewartet und weiterentwickelt, so die \citet{slicer2024}. Durch den Artikel von \citet[Seite
1327]{fedorov2012slicer} wird klar, dass MRML mehr ist also nur eine
Datenstruktur. Sie beschreiben MRML als Szenenorganisator von Bilder,
Anotationen, Layouts und Anwendungsstaten.

\citet[Seite 1331]{fedorov2012slicer} beschreiben die MRML-Datenstruktur als Schlüsselkomponenten
innerhalb von 3D Slicer. Dies ist auf die Softwarearchitektur von Slicer
zurückzuführen, die in Abbildung \ref{fig:3d_slicer_architektur} beschrieben wurde.
Die Kernanwendung von Slicer arbeitet wie bereits beschrieben nach dem MVC-Pattern.
MRML übernimmt hier den Teil des \textit{Models (M)} und bildet damit den
Grundstein der Anwendung \citep[vgl.][Seite 1332]{fedorov2012slicer}.

Die \citet{slicer2024} und der Artikel von \citet[Seite 1327]{fedorov2012slicer}
beschreibt MRML als XML-Format. Wird also eine MRML-Szenen gespeichert, so folgt
eine Speicherung als .mrml-Datei und damit unter der Haube als XML-Datei. Dabei wird
laut \citet{slicer2024} nur eine Referenz auf das Bild gespeichert. Die zu bearbeitende
Aufnahme selbst wird nicht inerhalb einer MRML-Datei abgespeichert.

MRML zeichnet sich vorallem dadurch aus, dass es eine Vielzahl an Dateiformaten
akzeptiert. Alle Formate, die für einen klinischen zweck verarbeitet werden, können
durch MRML untersützt werden. Um dies zu gewährleisten, ist die MRML Szene in sogenannte
\textit{nodes} aufgeteilt. Die basis Node-Typen folgen der \citet{slicer2024}
und sind in der folgenden Aufzählung zu sehen.

\begin{minipage}{0.45\textwidth}
	\begin{itemize}
		\item Data nodes

		\item Display nodes

		\item Storage nodes

		\item View nodes
	\end{itemize}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
	\begin{itemize}
		\item Plot nodes

		\item Subject hierarchy node

		\item Sequence node

		\item Parameter node
	\end{itemize}
\end{minipage}

Wird also ein Bild in eine MRML-Szene geladen, so speichert Slicer die
unterschiedlichen Eigenschaften eines Bildes in unterschiedlichen nodes. So werden
Beispielsweise basis Eigenschaften einer Probe im \textit{Data node} gespeichert,
wo hingegen ein \textit{Storage node} beschreibt wie eine \textit{Data node} in einer
Datei gespeichert wird. In \textit{Display node} werden die Eigenschaften zur Darstellung
eines Bildes hinterlegt. Der Hintergrund für die Speicherung von Probendaten in
unterschiedllichen nodes ist, dass beispielsweise das selbe Bild in unterschiedlichen
Formaten vorliegt oder ein und das selbe bild auf zwei unterschiedliche Arten visualisiert
werden soll. So kann sich Beispielsweise eine Struktur wie in Abbildung
\ref{fig:3d_slicer_class} ergeben.

\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{img/slicer_class_index.jpg}
	\caption{3D Slicer High Level Architektur nach \citet{slicer2024}}
	\label{fig:3d_slicer_class}
\end{figure}

Die Informationen in einem Bild werden also über dies Typen aufgeteilt und je nach
Sinn abgespeichert. Möchte man demnach auf die bestimmte Informationen in einer
Probe zugreifen. So kann diese Information über den Aufruf bestimmter Methoden erfolgen

\begin{lstlisting}[
	language={python},
	caption={Auslesen der Informationen aus den verschiedenen nodes},
	label={lst:_auslehsen_nodes}]
# data node - vtkMRMLVolumeNode
currentVolume.GetImageData()
# storage node - vtkMRMLStorableNode
currentVolume.GetStorageNode()
# display node - vtkMRMLDisplayableNode
currentVolume.GetDisplayNode()
\end{lstlisting}

Wie die Kommentaren in Listing \ref{lst:_auslehsen_nodes} bereits zeigen, gibt
es noch eine besonderheit von MRML. Damit ein Verwaltung aller Dateiformate möglich
ist, bedient sich MRML einiger Tools, die sich bereits etabliert haben. Die
wichtigsten sind hier bei \ac{VTK} und \ac{ITK} \citep[vgl.][]{vtk2024}, \citep[vgl.][]{itk2024}.
Dies beiden Tools sind echte Rießen in ihrere Branche. \ac{MRML} nutzt diese um
einige Dateiformate zu lessen und zu schreiben.

Durch das Betrachten der MRML-Szene wird klar, dass Slicer hierdurch viele Möglichkeiten
bietet. Speziell für die effiziente Speicherung der Proben in einer Szene durch
die unterschiedlichen node Typen. Ein besnoderer node, der gleichzeitig auch die
Brücker zu der interaktiven Benutzerschnittstelle von Slicer baut, ist der \textit{Parameternode}.
Warum dieser eine zentrale Rolle spielt und wie Slicer die Schnittstelle grundsätzlich
gestalltet, soll in Kapitel \ref{subsec:benutzerschnitstelle}
Benutzerschnitstelle diskutiert werden.
% ---------------------------------------------------------------------------------------

\subsection{Benutzerschnittstelle}
\label{subsec:benutzerschnitstelle} Für das erstellen eines \ac{UI}, das für
eine Slicer Extention nötig ist, nutzt 3D Slicer den Qt-Designer \citep[vgl.][]{qt2024}.
Die Integration des Qt-Designers als Applikation in eine andere Applikation funktioniert
aufgrund der Plattformintegrität, die der Designer mitbringt \citep[vgl.][]{qt2024}.
Dieser bietet so die Möglichkeit die benötigten Widgets über ein interaktives
User Interface zu bauen. Für dieses UI-Widget gibt es einen Gegenspieler im Quelltext
des Programmes, welcher als \textit{ParameterNode} bekannt ist. Der \textit{ParameterNode}
ist laut \citet{slicer2024} eine leichte Variante eines MRML-Node um
Parametereinstellungen zu speichern. Durch das Zusammenspiel zwischen UI-Widget und
\textit{ParameterNode} wird die UI automatisch aktualisiert, wenn sich das Programm
ändert und umgehert, so erklärt es die \citet{slicer2024}.

\begin{minipage}{0.35\textwidth}
	Das Erstellen der Verknüpfung zwischen UI-Widget und \textit{ParameterNode}
	erfolgt über die dynamische Eigenschaft \texttt{SlicerParameterName}, die
	direkt in der Komponentenansicht im Qt-Designer einstellbar ist. Die Abbidlung
	\ref{fig:qt_designer} soll diesen Vorgang verdeutlichen. Diese Verknüpfung
	lässt sich laut \citet{slicer2024} auch via Programmcode setzten.
\end{minipage}
\hfill
\begin{minipage}{0.55\textwidth}
	\centering
	\includegraphics[width=0.5\textwidth]{img/qt_designer.jpg}
	\captionof{figure}{Dynamische Eigenschaft einer Komponenten im Qt-Designer nach \citet{slicer2024}}
	\label{fig:qt_designer}
\end{minipage}

\texttt{widget.setProperty('SlicerParameterName', 'parameterName')}

Über das Objekt \textit{widget} kann die eigenschaft einer Komponente gesetzt werden,
ohne dass sie im Designer berührt werden muss.

Mit dem Ende dieses Abschnittes wurden alle wichtigen Bestandteile von 3D Slicer
abgedeckt und diskutiert, sowie alle weiteren Domänen eingeführt. So bleibt nun
die Frage nach dem Sinn dieser Arbeit. das Kapitel \ref{chap:fragestellung} soll
hier Klarheit liefern und die konkrete Fragestellung ausarbeiten.
% ---------------------------------------------------------------------------------------